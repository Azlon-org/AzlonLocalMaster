[
    {
        "role": "user",
        "content": "You are a Python coding assistant. Your task is to generate Python code for the following data analysis task.\nEnsure your code is self-contained, uses common libraries like pandas and numpy, and is ready to run.\nThe code will be executed within a function wrapper, so avoid top-level `if __name__ == '__main__':` blocks in your direct output.\nPrioritize generating actionable business insights, such as identifying trends, patterns, correlations, or anomalies in the data. While basic data cleaning might be necessary if data quality issues impede analysis, the primary goal is to uncover valuable information that can inform business decisions. If the 'Analysis Plan Task to Implement' is specifically about data cleaning or preparation, focus on that. Otherwise, aim for insightful analysis.\nProduce outputs that clearly communicate these insights. This includes printing statistical summaries and key observations to standard output, and generating informative visualizations (e.g., bar charts, line plots, scatter plots, heatmaps as appropriate for the data and task). Save all generated plots to files in the `data_directory_path` (which will be provided as a variable) and print a confirmation message to standard output stating the filename of the saved plot.\n\n**Business Context:**\nQuickWash operates a platform (app and website) that connects car detailers (\u201coperators\u201d) directly with customers. Customers request car wash services through the app, and detailers travel to the customer\u2019s location to perform the wash. The business model revolves around on-demand mobile car washing and detailing services with various service packages and potential extras.\n\n**Data Summary/Available Data:**\nNo data summary found.\n\n**Data Directory Path:**\nmulti_agents/competition/CarWash_Data\n\n**Analysis Plan Task to Implement:**\n**Data Cleaning and Validation**\n\nWhen loading data files (e.g., CSVs), assume a variable `data_directory_path` is predefined in the execution scope and contains the 'Data Directory Path' shown above. Construct full paths to data files using this variable and `os.path.join()`. For example, to load `orders.csv`, use `pd.read_csv(os.path.join(data_directory_path, 'orders.csv'))`.\nPlease include basic error handling, such as try-except blocks around file I/O operations and critical data processing steps.\nPlease provide ONLY the Python code block for this task, without any surrounding explanations unless they are comments within the code."
    },
    {
        "role": "assistant",
        "content": "```python\nimport os\nimport pandas as pd\nimport numpy as np\n\ndef clean_and_validate_data(data_directory_path):\n    # Helper function to load a CSV with error handling\n    def load_csv_safe(filename):\n        filepath = os.path.join(data_directory_path, filename)\n        try:\n            df = pd.read_csv(filepath)\n            print(f\"Loaded '{filename}' successfully with shape {df.shape}.\")\n            return df\n        except FileNotFoundError:\n            print(f\"Error: File '{filename}' not found in directory '{data_directory_path}'.\")\n        except pd.errors.ParserError:\n            print(f\"Error: Parsing error encountered while reading '{filename}'.\")\n        except Exception as e:\n            print(f\"Error: Unexpected error reading '{filename}': {e}\")\n        return None\n\n    # Load all relevant data files (assuming typical filenames)\n    orders = load_csv_safe('orders.csv')\n    operators = load_csv_safe('operators.csv')\n    customers = load_csv_safe('customers.csv')\n    services = load_csv_safe('services.csv')\n    extras = load_csv_safe('extras.csv')\n\n    # Store loaded dataframes in a dict for easy iteration and checks\n    data_frames = {\n        'orders': orders,\n        'operators': operators,\n        'customers': customers,\n        'services': services,\n        'extras': extras\n    }\n\n    # Basic data cleaning and validation\n    for name, df in data_frames.items():\n        if df is None:\n            print(f\"Skipping validation for '{name}' as it failed to load.\")\n            continue\n\n        print(f\"\\n--- Data Validation for '{name}' ---\")\n        # Check for duplicates\n        dup_count = df.duplicated().sum()\n        print(f\"Duplicate rows: {dup_count}\")\n        if dup_count > 0:\n            print(f\"Removing duplicates from '{name}'.\")\n            df.drop_duplicates(inplace=True)\n\n        # Check for missing values summary\n        missing = df.isna().sum()\n        missing_total = missing.sum()\n        print(f\"Total missing values: {missing_total}\")\n        if missing_total > 0:\n            print(\"Missing values per column:\")\n            print(missing[missing > 0])\n\n        # Check for columns with zero variance (constant columns)\n        nunique = df.nunique(dropna=False)\n        const_cols = nunique[nunique <= 1].index.tolist()\n        if const_cols:\n            print(f\"Columns with zero or one unique value (constant columns): {const_cols}\")\n\n        # Example specific checks per file\n        if name == 'orders':\n            # Check for expected columns\n            expected_cols = ['order_id', 'customer_id', 'operator_id', 'service_id', 'order_date', 'price', 'status']\n            missing_cols = [c for c in expected_cols if c not in df.columns]\n            if missing_cols:\n                print(f\"Warning: Missing expected columns in orders: {missing_cols}\")\n\n            # Validate date columns\n            if 'order_date' in df.columns:\n                try:\n                    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n                    null_dates = df['order_date'].isna().sum()\n                    if null_dates > 0:\n                        print(f\"Warning: {null_dates} invalid/missing dates in 'order_date' column.\")\n                except Exception as e:\n                    print(f\"Error parsing 'order_date': {e}\")\n\n            # Validate price - should be non-negative\n            if 'price' in df.columns:\n                negative_prices = (df['price'] < 0).sum()\n                if negative_prices > 0:\n                    print(f\"Warning: {negative_prices} orders have negative price values.\")\n\n        if name == 'operators':\n            # Check for unique operator_id\n            if 'operator_id' in df.columns:\n                dup_ops = df['operator_id'].duplicated().sum()\n                if dup_ops > 0:\n                    print(f\"Warning: {dup_ops} duplicated operator_id values.\")\n\n        if name == 'customers':\n            if 'customer_id' in df.columns:\n                dup_cust = df['customer_id'].duplicated().sum()\n                if dup_cust > 0:\n                    print(f\"Warning: {dup_cust} duplicated customer_id values.\")\n\n        # Replace original df with cleaned df in dict\n        data_frames[name] = df\n\n    print(\"\\nData cleaning and validation completed.\")\n\n    # Return cleaned dataframes dictionary for downstream use if needed\n    return data_frames\n```"
    }
]