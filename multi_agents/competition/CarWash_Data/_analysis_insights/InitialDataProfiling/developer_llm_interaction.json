[
    {
        "role": "user",
        "content": "You are a Python coding assistant. Your task is to generate Python code for the following data analysis task.\nEnsure your code is self-contained, uses common libraries like pandas and numpy, and is ready to run.\nThe code will be executed within a function wrapper, so avoid top-level `if __name__ == '__main__':` blocks.\nCRITICAL INSTRUCTION: DO NOT GENERATE VISUALIZATIONS OR PLOTS. Other agents cannot interpret them.\nInstead, focus EXCLUSIVELY on calculating and PRINTING concrete numerical statistics, percentages, counts and insights as text.\nPrint all key findings with clear labels and formatting in the console output.\n\nPrioritize generating actionable business insights, such as:\n- Summary statistics (mean, median, percentiles) for key metrics\n- Distribution analyses with concrete percentages\n- Top/bottom N items with exact counts and percentages\n- Growth rates and changes over time expressed numerically\n- Correlations between variables with coefficient values\n\n**Business Context:**\nNo business context found.\n\n**Data Summary/Available Data:**\nNo data summary found.\n\n**Data Directory Path:**\nmulti_agents/competition/CarWash_Data\n\n**Analysis Plan Task to Implement:**\n**Service Package and Extra Services Analysis**\n\nWhen loading data files (e.g., CSVs), assume a variable `data_directory_path` is predefined in the execution scope.\nConstruct full paths using `os.path.join(data_directory_path, 'filename')`.\nPlease include basic error handling, such as try-except blocks around critical operations.\nPlease provide ONLY the Python code block for this task, without surrounding explanations unless they are comments."
    },
    {
        "role": "assistant",
        "content": "```python\nimport os\nimport pandas as pd\nimport numpy as np\n\ndef analyze_service_packages_and_extras(data_directory_path):\n    try:\n        # Load main data file - assuming a relevant file name for service package and extra services\n        file_path = os.path.join(data_directory_path, 'car_wash_transactions.csv')\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f\"ERROR: File not found at path: {file_path}\")\n        return\n    except Exception as e:\n        print(f\"ERROR: Unable to load data due to: {e}\")\n        return\n\n    # Check columns to understand data structure\n    print(\"Columns in dataset:\", df.columns.tolist())\n\n    # Assuming columns like 'ServicePackage', 'ExtraServices', 'TransactionDate', 'Price', 'CustomerID' exist\n    # Adjust column names if necessary based on actual data\n\n    # Basic data info\n    print(f\"\\nTotal transactions loaded: {len(df)}\")\n\n    # Clean data: drop rows with missing critical info in ServicePackage or Price\n    df_clean = df.dropna(subset=['ServicePackage', 'Price'])\n    dropped = len(df) - len(df_clean)\n    if dropped > 0:\n        print(f\"Dropped {dropped} transactions due to missing ServicePackage or Price\")\n\n    # Summary statistics on Price by ServicePackage\n    print(\"\\n--- Price Summary Statistics by Service Package ---\")\n    package_stats = df_clean.groupby('ServicePackage')['Price'].agg(['count', 'mean', 'median', 'min', 'max',\n                                                                    lambda x: np.percentile(x, 25),\n                                                                    lambda x: np.percentile(x, 75)])\n    package_stats.columns = ['Count', 'Mean Price', 'Median Price', 'Min Price', 'Max Price', '25th Percentile', '75th Percentile']\n    print(package_stats.sort_values('Count', ascending=False).to_string(float_format='${:,.2f}'.format))\n\n    # Distribution of Service Packages (percentage of total transactions)\n    total_tx = len(df_clean)\n    service_dist = df_clean['ServicePackage'].value_counts(normalize=True).mul(100).round(2)\n    print(\"\\n--- Service Package Distribution (Percentage of Transactions) ---\")\n    for pkg, pct in service_dist.items():\n        print(f\"{pkg}: {pct:.2f}%\")\n\n    # Analyze Extra Services\n    # Assume 'ExtraServices' is a string column with comma-separated extras or NaN if none\n    df_clean['ExtraServices'] = df_clean['ExtraServices'].fillna('')\n    # Extract all extra services into a list and explode\n    df_clean['ExtraServicesList'] = df_clean['ExtraServices'].apply(lambda x: [e.strip() for e in x.split(',') if e.strip()] if x else [])\n    extras_series = df_clean.explode('ExtraServicesList')['ExtraServicesList']\n\n    # Count and percentage of transactions with extras\n    with_extras = df_clean[df_clean['ExtraServicesList'].map(len) > 0]\n    pct_with_extras = len(with_extras) / total_tx * 100\n    print(f\"\\nPercentage of transactions with at least one extra service: {pct_with_extras:.2f}%\")\n\n    # Top 10 most popular extra services with counts and percentages\n    extras_counts = extras_series.value_counts()\n    extras_pct = (extras_counts / total_tx * 100).round(2)\n    print(\"\\n--- Top 10 Extra Services by Count and Percentage of All Transactions ---\")\n    top_n = 10\n    for extra, count in extras_counts.head(top_n).items():\n        pct = extras_pct.loc[extra]\n        print(f\"{extra}: {count} transactions, {pct:.2f}% of all transactions\")\n\n    # Average price difference for transactions with extras vs without extras\n    avg_price_with_extras = with_extras['Price'].mean()\n    avg_price_without_extras = df_clean[df_clean['ExtraServicesList'].map(len) == 0]['Price'].mean()\n    print(f\"\\nAverage Price with Extras: ${avg_price_with_extras:.2f}\")\n    print(f\"Average Price without Extras: ${avg_price_without_extras:.2f}\")\n    price_diff = avg_price_with_extras - avg_price_without_extras\n    print(f\"Average price increase due to extras: ${price_diff:.2f}\")\n\n    # Growth/Change over time analysis on service package usage\n    # Assuming 'TransactionDate' is available and parseable\n    try:\n        df_clean['TransactionDate'] = pd.to_datetime(df_clean['TransactionDate'])\n    except Exception:\n        print(\"\\nWARNING: Could not parse 'TransactionDate' column for time-based analysis.\")\n        return\n\n    df_clean['YearMonth'] = df_clean['TransactionDate'].dt.to_period('M')\n    monthly_counts = df_clean.groupby(['YearMonth', 'ServicePackage']).size().unstack(fill_value=0)\n\n    # Calculate month-over-month percentage growth for top 3 packages by total counts\n    top_packages = monthly_counts.sum().sort_values(ascending=False).head(3).index.tolist()\n    print(\"\\n--- Month-over-Month Growth Rates for Top 3 Service Packages ---\")\n    for pkg in top_packages:\n        counts = monthly_counts[pkg]\n        growth = counts.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0) * 100\n        avg_growth = growth.mean()\n        print(f\"{pkg}: Average MoM Growth = {avg_growth:.2f}%\")\n        # Print last 3 months growth for recent insight\n        print(f\"Last 3 months MoM growth for {pkg}:\")\n        for date, g in growth[-3:].items():\n            print(f\"  {date}: {g:.2f}%\")\n\n    # Correlation between number of extra services and price\n    df_clean['NumExtras'] = df_clean['ExtraServicesList'].apply(len)\n    corr = df_clean[['NumExtras', 'Price']].corr().loc['NumExtras', 'Price']\n    print(f\"\\nCorrelation between number of extras and price: {corr:.3f}\")\n\n```"
    }
]